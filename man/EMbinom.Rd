% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/EM_binom.R
\name{EMbinom}
\alias{EMbinom}
\title{Fit mixture of two binomial distributions using EM.}
\usage{
EMbinom(Y, N, iniL, iniPI1, iniPI2, max.iter = 500, tolerance = 0.001)
}
\arguments{
\item{Y}{vector of length V with the observed data (number of successes)}

\item{N}{the amount of trials}

\item{iniL}{initial value for \eqn{\lambda}}

\item{iniPI1}{initial value for \eqn{\pi_1}{\pi 1}}

\item{iniPI2}{initial value for \eqn{\pi_2}{\pi 2}}

\item{max.iter}{maximum iterations (optional)}

\item{tolerance}{level of tolerance when comparing the likelihood of previous and current step in the algorithm (optional). Convergence is assumed when the absolute difference between both log likelihoods is smaller than the tolerance level.}
}
\value{
Data frame with the parameter estimates and the number of iterations after convergence
}
\description{
Function to estimate the parameters of a mixture of two binomial distributions
using the Expectation-Maximization algorithm (EM).
Can be used in a setting where the data contains V independent observations.
Each of these is a realization of a binomial data generating process with the
probability of success (out of N trials) being either \eqn{\pi_1}{\pi 1} or \eqn{\pi_2}{\pi 2}.
}
\details{
Assume \eqn{Y} is i.i.d. from \deqn{\lambda P_1(Y;k, \pi_1) + (1 - \lambda) P_2(Y;k,\pi_2)}{\lambda P1(Y;k, \pi 1) + (1 - \lambda) P2(Y;k,\pi 2)}
The complete log-likelihood of the data over all observations (V) is then given as:
\deqn{cst + \sum_{v = 1}^V log(\lambda(\pi 1)^Y(v) (1 - \pi 1)^(N - Y(v)) + (1 - \lambda)(\pi 2)^Y(v) (1 - \pi 2)^(N - Y(v)))}
The EM algorithm is then used to estimate \eqn{\lambda}, \eqn{\pi_1}{\pi 1} and \eqn{\pi_2}{\pi 2}.

Note on starting values: it is not advised to use the same values for the starting values
of \eqn{\pi_1}{\pi 1} and \eqn{\pi_2}{\pi 2} as the algorithm does not seem to handle this
setting very well. Starting values far away from the true value do converge to the true value
most of the time, but take more iterations.
}
